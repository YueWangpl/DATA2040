{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Cassava Leaf Disease Classification Part 3- Yue, Tianqi.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "TPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/YueWangpl/DATA2040/blob/main/Cassava_Leaf_Disease_Classification_Part_3_Yue%2C_Tianqi.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "NXQT7EkIdxHj"
      },
      "source": [
        "## Introduction"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "GAv7HqU287y1"
      },
      "source": [
        "Hello, we are one of the contesting teams for Kaggle's Cassava Leaf Disease Classification challenge. The team members are Yue Wang and Tianqi Tang, both from Brown University's Data Science Initiatives.\n",
        "\n",
        "Cassava roots are a good source of carbohydrates, vitamin C, thiamine, riboflavin, and niacin. Cassava leaves, if prepared properly, can contain up to 25 percent protein. As a resilient crop, cassava is resistant to heat and does not require much fertilizer. However, it is vulnerable to bacterial and viral diseases. One way to detect the diseases is to examine the look of cassava leaves. Therefore, it is important to identify different diseases affecting cassava leaves based on the images, which, with the utilization of deep learning, is exactly what this project tries to accomplish. We hope that our modest contribution will be useful for the development of cassava disease treatments.\n",
        "\n",
        "We deployed our deep learning model based on ResNet-50. Our model achieved above 0.72 accuracy on the test sets. In the following sections, we will discuss about the architectures of our model, the hyperparameters, the optimization and possible future improvements. Various links relevant to our work are shown at the end of this notebook."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "S0P17Y3Ed38g"
      },
      "source": [
        "## Model Architecture"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ML1QVN9nkJmN"
      },
      "source": [
        "We've employed an ensembled model consisting of three independent sub-models with the same structures, yet different hyperparameters and `randome_state` in the `train_test_split` function from the *sklearn* library.  \n",
        "For each sub-model, it employed a ResNet-50 as the base model with pretrained weights on *ImageNet*.  \n",
        "<img src=\"https://miro.medium.com/max/700/1*_nmPcwwnsHE-AC69ASkj9w.jpeg\" alt=\"ResNet Architecture\">\n",
        "<center><b>ResNet Architecture <a href=\"https://towardsdatascience.com/architecture-comparison-of-alexnet-vggnet-resnet-inception-densenet-beb8b116866d\">[1]</a></b></center>\n",
        "\n",
        "We usually want to go deeper in networks so that the network can learn the subtle features we may want it to notice. However, deeper networks may cause overfit easily and the accuracy starts to decrease after a certain depth, because all of the layers are fighting with each other and newer layers are trying to study what was outputed from the last layer. Imagine a scenario that a CNN is trained to tell the difference between a basketball from a room door. The network have learned that they have different shapes, but the later layers goes into details such as colors, textures and if they have a door knob which the CNN classifier might make mistakes on, because a drop of water on the basketball might be similar to the presence of door knob, and there might be doors wrapped with rubber, just like the cover of a basketball.  \n",
        "Obviously, for this simple task, the most important factor this classifier needs is just the shape of these two objects. It will be so easy for the model, or for human to distinguish a sphere from a cuboid, so we would not like this feature to be ruled out by over training the network.\n",
        "\n",
        "ResNet is a model with more than 100 layers, yet acieves better results comparing with other such deep convolutional networks because of the concatenation of the input on the output for each residual block. So that features learned by previous layers will be kept after every new set of convolutional layers as an offset to overly deep neural networks."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "2hbh-Bpu2gtp"
      },
      "source": [
        "The model does not include top layers of ResNet-50. Instead, after the convolution layers of ResNet-50, we added a global average pooling layer, then flattened, and added two dense layers with ReLu activations. The dense layers have output sizes of 512 and 256, and each of them is followed by a batch normalization layer and a dropout layer.  \n",
        "The final layer is anoter dense layer with 5 nodes, which matches the number of classes. It uses softmax as the activation function to offer the probabilities of each class.\n",
        "\n",
        "<center><img src=\"https://lh4.googleusercontent.com/7VUZlhPScFEZ9_yq_sm3Khmb9E_2d8Xwhc6wx126vEdJxdaXaQUtxNdXLjpL2xzpjv_nL8hU7bnjpT_33A_qBG-lT9eFJee14Jg0z4AuNGRJan3q4_gOyzuRrisVv8NX3gCRcyI_\" alt=\"ResNet Structure\"><center>\n",
        "<center><b>Performances of different learning rates</b></center>\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "CBYmydt5_aMd"
      },
      "source": [
        "\n",
        "We use Adam as the optimizer. The loss and the metrics are sparse_categorical_crossentropy and sparse_categorical_accuracy, respectively.\n",
        "\n",
        "\n",
        "For fitting, we adopt learning rate scheduling and early stopping.\n",
        "\n",
        "We fit the model for 500 epochs but the training terminates well before that limit due to early stopping.\n",
        "\n",
        "Finally, we take the 3 trained sub-models and average out their prediction probabilities as the prediction of our final ensemble model.\n",
        "\n",
        "<center><img src=\"https://lh4.googleusercontent.com/cDmcygmxCz5Mfi5alvkkl8VoY847DmCJbCBo-FjN46MKHeiqd5aUzllZEePN1ZfGIKx_VMCod7YHxJ2RQXEhWpt2m0mpth4Kcz64f9VLi--6JQL6nl_NjSGOd4iOwZwrn495vrxI\" alt=\"Ensemble Model\"><center>\n",
        "<center><b>Ensemble Model</b></center>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "it-oBr6us9I4"
      },
      "source": [
        "## Hyperparameter Selection"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "x1XyNmjqtAIW"
      },
      "source": [
        "### Unfreeze base model layers?\n",
        "\n",
        "We did not unfreeze the original ResNet model layers after comparing metrics of 'unfreeze first 30 layers1, 'unfreeze last 30 layers', and 'unfreeze all'. Small learning rate as $1e-8$ were used, yet the model with unfreezed layers still cannot beat an accuracy of 64%.  \n",
        "A [StackOverFlow about unfreezing layers](https://stackoverflow.com/questions/64227483/what-is-the-right-way-to-gradually-unfreeze-layers-in-neural-network-while-learn) was viewed and one of the response says that there are cases where $1e-8$ can be too much. I'm not sure if it's the case of our situation as well.\n",
        "\n",
        "<center><img src=\"https://lh4.googleusercontent.com/B5uohwVkWx2W9nf08PchqoIkxL02kAz2Nwr_pcebs1eRWSGjHXIg_rR2KX7xlYaOj4IpQ80n0hTg1gjQaFMut4QOb-uHaAw8_oPG81loK2x5OMf96Vw6cgh45RlY8ZEAFvLQEYL8\"><center>\n",
        "<center><b>Unfreeze All</b></center>\n",
        "Training accuracy exceeds the validation accuracy too much.\n",
        "\n",
        "<center><img src=\"https://lh4.googleusercontent.com/AgVYAR9bDEsEFxgR3bZG8iy7HRQqnashjLJq0QzGcgvyCENHh5RkiQmzxIxVagJqygV9_MLkqB2fzOXjnORb_zXUZu1F_A5o-4SVwhqm1l-e_TLqUZUQiSdb86f_Ysg7lsAFjiWp\"><center>\n",
        "<center><b>Unfreeze First 30 Layers</b></center>\n",
        "Validation accuracy stayed to be 0.1~0.2, yet training loss as in a decrease.\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ZdLCWXFSC5uo"
      },
      "source": [
        "And when unfreeze the last 30 layers, the validation accuracy stayed around 0.6 with the highest to be 0.6462 after 100 epochs."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "sycVbQtPw7SW"
      },
      "source": [
        "### Optimizer?\n",
        "We've tested four different optimizers, namely adagrad, adam, adadelta, and rmsprop, while every other hyperparameters to remain the same to compare their performances and determind on the one that can find the minimum in the most stable way with 15 epochs each, and here is the plot of their behavior:\n",
        "<center><img src=\"https://lh6.googleusercontent.com/xogtVtiT4zDFqZWmwgzDmfw6Ae7j6qLnAqtcdICK5ENRBM-CkyC-59Zzpk6A9cnGeulWhhDiKkQ9ftWSKFuT6bV3v1AX5-CSqgPljK45Eb1BmWEVPiFoAwY8I94geTyvBYDiruh1\" alt=\"Optimizer performances of adagrad, adam, adadelta, rmsprop\"><center>\n",
        "<center><b>Optimizer performances of adagrad, adam, adadelta, rmsprop</b></center>\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "J56copxY2Twy"
      },
      "source": [
        "Adadelta seems to perform better than others, which makes it a winner here."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "6NBzRNyF1YU4"
      },
      "source": [
        "### Learning Rate?\n",
        "\n",
        "With a similar approach, learning rate is compared with in 15 epochs with the plot showing their behavior:\n",
        "\n",
        "<center><img src=\"https://lh5.googleusercontent.com/PrVEMVP3-VLYMQ9XqF7pQtmv2diT3doFtR2SYZS1Ntj5slMxDp7WexX8MaVU80WywsmkxI_ZWs7EIfjVMZqtfz7gK9mTz8WBB-kyKtO8A2cVxVf71-LRT_tMeDUHXmun6cgKuTqU\" alt=\"Performances of different learning rates\"><center>\n",
        "<center><b>Performances of different learning rates</b></center>\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Ozhtiz8-7fe_"
      },
      "source": [
        "$1e-4$ was considered to be more stable in performance. However, it’s observed that all learning rates gives a bumpy behavior, so before we make a final decision, we’ve use a callback function of LearningRateScheduler to graph the training and validation loss.\n",
        " \n",
        "```\n",
        "tf.keras.callbacks.LearningRateScheduler(lambda epoch: 1e-8*10**(epoch/20))\n",
        "```\n",
        " \n",
        "The resulted plot is shown below:\n",
        " \n",
        "<center><img src=\"https://lh6.googleusercontent.com/7YzCb5OmpWrdpaqwN-j121Pnw5of55QPdE9fv55OiKzgkbS31ZuSP1G29KwUZ9Mss8y0kDl35vL5pYQdlp3Gb-89sI3j3M1kfDTVJf2EJIJLVUSXt8kiCXoRXHpboimG_5ACkBLm\" alt=\"Callback to compare lr\"><center>\n",
        "<center><b>Callback to compare lr</b></center>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "pwdRpwLy-vME"
      },
      "source": [
        "All learning rates below $1e-4$ and above $1e-8$ were leading us to lower losses smoothly. Hence, $1e-4$ was decided to be used as our learning rate."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "MqgjSG0320LS"
      },
      "source": [
        "### Decay Rate?\n",
        "\n",
        "After that, different decay rates in `tf.keras.optimizers.schedules.ExponentialDecay` were also compared. However, since epoch of 15 is just a small amount"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "1WOhnQMttYnl"
      },
      "source": [
        "So all of the above are hyperparameters chosen.  \n",
        "Here is the behavior of our final model with an early stopping callback:\n",
        "<center><img src=\"https://lh3.googleusercontent.com/PN43RckvJb5DUqbKwiJfensjGpRualYYdg284KEDoValrSIurlC__WJ4_xZTflcbzTWxuhZCzfS0XAyTQIGdYGygsLBoATs1lrkCnjni-FrvQuE9V02UQB9G3Zd1oHHZp4wTV6nD\" alt=\"3 models and the ensembled model\"><center>\n",
        "<center><b>3 models and the ensembled mode</b></center>\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "6sGgJM_1DmnK"
      },
      "source": [
        "And as we said, we ensembled 3 models trained under different ramdom states during train/ test split.  \n",
        "And here is the accuracy of half of our dataset:\n",
        "\n",
        "<center><img src=\"https://lh5.googleusercontent.com/GJT9j6JdF2ixBwqTf00tEPEZQfvVt_9AOCsVIwKg3yroODgvTnvwrZFABS82blaJZ3vID67lH1A5fY5Y9kXSOeLtzjj4-9cMvrC_Vb985hxQdpU6gkgRlzm0X_eCfAHrb5GZuSbV\" alt=\"3 models and the ensembled model\"><center>\n",
        "<center><b>Accuracy of local dataset</b></center>\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Nndlae3SD1FY"
      },
      "source": [
        "Here is the difference of accuracy after submission, with the one on the bottom to be the ensembled model.\n",
        "<center><img src=\"https://lh4.googleusercontent.com/wcrdllFYKsRzH3vC_FN0wzNzjCpv_8fCIK44iGKyLpvub4aBcdKtnDH16McXOodMBnR5dfl5kDgJVcxx-B_hUpS0BYWDFLerWTl1wwxBz6-uxWrsr9HqcocFErv8n6QqZ2lxvSxQ\" alt=\"3 models and the ensembled model\"><center>\n",
        "<center><b>3 models and the ensembled mode</b></center>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "A9FvpUtViqvz"
      },
      "source": [
        "## Next Steps\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "iV5o6VKlYz20"
      },
      "source": [
        "Due to the lack of time, we were unable to implement some techniques that may boost the accuracy of our model further.\n",
        "\n",
        "1. Create a more balanced dataset. Our dataset is imbalanced as with more than 60% of the data belong to one class and there are 5 classes in total. This may cause a bias to our model as predicting any data to be the majority class will yield a decent accuracy, but then the model will performs poorly on predicting minority classes. By constructing a balanced dataset, this concern can be avoided and our model may not be biased towards the majority class.\n",
        "\n",
        "2. More fine tuning. We did not have enough time to fine tune various hyperparameters, and we wish to keep fine tuning if we were given more time.\n",
        "\n",
        "3. Exploiting more models. We have tried various models including VGG, MobileNet, EfficientNet, etc. Among them, ResNet yields the best results. But this may not be conclusive as we did not fully explore many of the models.\n",
        "\n",
        "4. Collaborating with other teams. We wish to collaborate with other Kaggle teams to produce a better model."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "4X8nItU_Gjdc"
      },
      "source": [
        "## Kaggle Submission\n",
        "\n",
        "<img src=\"https://lh4.googleusercontent.com/dhTKyU9om0zrPXQ22QD1R5NEywoWvXmBsSvf9MsIrhV2yKJTanr_r3tJdJ0deji_LX16Vd8QrtL9dkT1m84hhVw-pqd3P8hkeJQ44VvaaEsjuq2D1ixrhOnZDcVTXTxwUkIdp4pd\">"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "6wZ4JRRookkv"
      },
      "source": [
        "## Links"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ptsTVIBpomQa"
      },
      "source": [
        "[Github Repo](https://github.com/YueWangpl/DATA2040)\n",
        "\n",
        "[Kaggle Notebook Saved in Git Repo](https://github.com/YueWangpl/DATA2040/blob/main/tune-resnet-cassava-leaf-disease.ipynb)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "vuWLS_UPi0Gq"
      },
      "source": [
        "## References "
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "e2plzzgbncmI"
      },
      "source": [
        "\n",
        "[Sample Submission from Dan](https://www.kaggle.com/danpotter/blind-monkey-submission-example-data2040-sp21)  \n",
        "[Sample model from Kaggle](https://www.kaggle.com/jessemostipak/getting-started-tpus-cassava-leaf-disease)  \n",
        "[Ensemble keras models](https://medium.com/randomai/ensemble-and-store-models-in-keras-2-x-b881a6d7693f)  \n",
        "[Ensemble models with scikit-learn](https://sailajakarra.medium.com/ensemble-scikit-learn-and-keras-be93206c54c4)  \n",
        "[Save and load sklearn models](https://machinelearningmastery.com/save-load-machine-learning-models-python-scikit-learn//) \n",
        "[StackOverFlow about unfreezing layers](https://stackoverflow.com/questions/64227483/what-is-the-right-way-to-gradually-unfreeze-layers-in-neural-network-while-learn)  \n"
      ]
    }
  ]
}